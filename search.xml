<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Encoder-Decoder详解及其数学本质</title>
    <url>/2022/12/04/Encoder-Decoder%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%85%B6%E6%95%B0%E5%AD%A6%E6%9C%AC%E8%B4%A8/</url>
    <content><![CDATA[<h5 id="前言：encoder-decoder-也即-编码器-解码器-结构，它属于一种抽象性的结构，并不表示某一具体结构，在下文可以看到有许多机器学习算法都服从这一结构。"><a href="#前言：encoder-decoder-也即-编码器-解码器-结构，它属于一种抽象性的结构，并不表示某一具体结构，在下文可以看到有许多机器学习算法都服从这一结构。" class="headerlink" title="前言：encoder-decoder 也即 编码器-解码器 结构，它属于一种抽象性的结构，并不表示某一具体结构，在下文可以看到有许多机器学习算法都服从这一结构。"></a>前言：encoder-decoder 也即 编码器-解码器 结构，它属于一种抽象性的结构，并不表示某一具体结构，在下文可以看到有许多机器学习算法都服从这一结构。</h5><h5 id="引入："><a href="#引入：" class="headerlink" title="引入："></a>引入：</h5><p>在机器学习中，很多问题可以抽象出类似的模型：</p>
<ul>
<li>机器翻译。将一种语言的句子转化成另外一种语言的句子。</li>
<li>自动摘要。为一段文字提取出摘要。</li>
<li>为图像生成文字解说。将图像数据转化成文字数据。</li>
<li>根据一段文字描述生成图像。这是上面问题的反过程，将文字转化成图像。</li>
</ul>
<p>其它的例子我们就不一一列举。在这些问题中，我们需要将输入数据转化成另外一种输出数据，<font color=blue><strong>二者之间有概率关系</strong></font>。例如，对于机器翻译来说，二者有相同的语义。</p>
<p>但是，这些情况下直接用一个函数完成这个转化 y&#x3D;f(x)可能会存在困难。例如对机器翻译来说<font color=blue>输入和输出的长度是不固定的</font>，二者还可能不相等。因此我们需要先将输入数据x转化成一种中间数据z，再从z映射出y。这就是编码器-解码器结构。（不固定x——固定z——不固定y）</p>
<h3 id="从PCA说起"><a href="#从PCA说起" class="headerlink" title="从PCA说起"></a>从PCA说起</h3><p>主成分分析是一种经典的无监督数据降维算法。它将一个高维的向量x映射成一个低维的向量y，前提条件是y很好的保留了x的主要信息。在做数据降维时，我们执行如下变换：$$y&#x3D;W(x-m)$$。计算过程很简单，先减掉均值向量，然后左乘投影矩阵即可。其中m是样本集的均值向量，W是投影矩阵，通过样本集计算得到，具体的原理可以参考$$PCA$$的教程。这一投影过程的作用类似于编码器，将高维向量x编码成低维向量y。</p>
<p>有些时候，我们需要从降维后的向量y重构出原始的向量x，这可以通过数据重构算法实现，重构变换方法即$$W^Ty+m$$，这刚好和投影算法相反，是先左乘投影矩阵W的转置， 然后加上均值向量。在这里，重构算法可以看作是解码器，从降维后的向量解码出原始的信号。</p>
<h3 id="自动编码器-Auto-Encoder"><a href="#自动编码器-Auto-Encoder" class="headerlink" title="自动编码器 Auto Encoder"></a>自动编码器 Auto Encoder</h3><p>自动编码器（Auto-Encoder，简称AE）是一种特殊的神经网络，用于特征提取和数据降维。最简单的自动编码器由一个输入层，一个隐含层，一个输出层组成。隐含层的映射充当编码器，输出层的映射充当解码器。</p>
<p>训练时编码器对输入向量进行映射，得到编码后的向量；解码器对编码向量进行映射，得到重构后的向量，它是对输入向量的近似。编码器和解码器同时训练，训练的目标是最小化重构误差，即让重构向量与原始输入向量之间的误差最小化，这与PCA非常类似。因此样本x的标签值就是样本自身。</p>
<p>训练完成之后，在预测时只使用编码器而不再需要解码器，编码器的输出结果被进一步使用，用于分类，回个等任务。</p>
]]></content>
  </entry>
  <entry>
    <title>hexo插入图片</title>
    <url>/2023/03/22/hexo%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87/</url>
    <content><![CDATA[<h5 id="hexo博客插入图片"><a href="#hexo博客插入图片" class="headerlink" title="hexo博客插入图片"></a>hexo博客插入图片</h5><p><a href="https://blog.csdn.net/m0_43401436/article/details/107191688">hexo博客中插入图片失败——解决思路及个人最终解决办法_hexo 出现重复路径_金牛大王的博客-CSDN博客</a></p>
]]></content>
      <tags>
        <tag>hexo博客帮助文档</tag>
      </tags>
  </entry>
  <entry>
    <title>摘抄录</title>
    <url>/2022/10/04/%E6%91%98%E6%8A%84%E5%BD%95/</url>
    <content><![CDATA[<p>万家墨面没蒿莱，敢有歌吟动地哀。心事浩茫连广宇，于无声处听惊雷。<br>——鲁迅《无题·万家墨面没蒿莱》<br>译文：黎民百姓们像黑瘦的囚徒，流离失所于荒野，哪还敢有慷慨悲歌，引发动地的哀声。我心里想的事很多、很远，连通着广大国土上的人民，所以从表面沉寂中，我能听到革命春雷的萌动。</p>
<p>​        我们自古以来，就有埋头苦干的人，有拼命硬干的人，有为民请命的人，有舍身求法的人，……虽是等于为帝王将相作家谱的所谓“正史”，也往往掩不住他们的光耀，这就是中国的脊梁。<br>​        这一类的人们，就是现在也何尝少呢？他们有确信，不自欺；他们在前仆后继地战斗，不过一面总在被摧残，被抹杀，消灭于黑暗中，不能为大家所知道罢了。说中国人失掉自信力，用于指一部分人则可，倘若加于全体，那简直是污蔑。<br>​        要论中国人，必须不被搽在表面的自欺欺人的脂粉所诓骗，却看看他的筋骨和脊梁。自信力的有无，状元宰相的文章是不足为据的，要自己去看地底下。<br>——鲁迅《中国人失掉自信力了吗？》</p>
]]></content>
  </entry>
  <entry>
    <title>.sh脚本编写</title>
    <url>/2023/03/22/sh%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99/</url>
    <content><![CDATA[<p>linux下用.sh文件执行python命令</p>
<p>假设要在终端执行的命令是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure>

<p>首先，在执行目录下创建run.sh文件，并在run.sh文件中写入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure>

<p>并保存。</p>
<p>假设train.py是可以输入参数的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python train.py --train --epoches 5</span><br></pre></td></tr></table></figure>

<p>以上命令代表让模型训练，并且训练5轮。于是，在.sh文件中这样写</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python train.py --train --epoches 5</span><br></pre></td></tr></table></figure>

<p>并保存。</p>
<p>假如你希望这个命令执行10次，那么在.sh文件中这样写</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> 1 2 3 4 5 6 7 8 9 10</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">	python train.py --train --epoches 5</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<p>编写好shell文件后，下面是如何在Windows+pycharm环境下使用pycharm运行shell文件</p>
<p>①首先在本机上安装git，并测试git是否安装成功。</p>
<p>测试方法是：右键点击桌面，如果出现“git bash here”等选项，说明安装成功。</p>
<img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230322123825585.png" alt="image-20230322123825585" style="zoom:50%;" />

<p>②设置pycharm的terminal</p>
<p>点击file——settings——tools——terminal——shell path，将cmd.exe改成刚刚下载的git路径。注意选择的路径是sh.exe，不是git.exe</p>
<img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230322124708085.png" alt="image-20230322124708085" style="zoom:80%;" />
]]></content>
      <tags>
        <tag>linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title>编程笔记【4.3】</title>
    <url>/2023/04/03/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0%E3%80%904-3%E3%80%91/</url>
    <content><![CDATA[<h5 id="Python-之-使用argparse模块编写命令行接口"><a href="#Python-之-使用argparse模块编写命令行接口" class="headerlink" title="Python 之 使用argparse模块编写命令行接口"></a>Python 之 使用argparse模块编写命令行接口</h5><p>argparse模块是Python内置的一个用于命令行选项、参数和子命令解析器的模块。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建一个解析器，即一个ArgumentParser对象</span></span><br><span class="line">parser=argparse.ArgumentParser(description=<span class="string">&#x27;Full Pipeline Training&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加参数</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--data_path&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;/path/to/data&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;root dir that contain train data and test data. &#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;--ckpt&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;/path/to/ckpt&#x27;</span>, metavar=<span class="string">&#x27;PATH&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;path to the latest checkpoint (default: model)&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--gpu&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, nargs=<span class="string">&#x27;+&#x27;</span>, default=[<span class="number">6</span>], <span class="built_in">help</span>=<span class="string">&#x27;select gpu. &#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--train&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&#x27;If true, the model will train, else only validate. &#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--alpha&#x27;</span>, require=<span class="literal">True</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;alpha in the modal. &#x27;</span>)</span><br><span class="line"><span class="comment"># 使用</span></span><br><span class="line">args=parser.parse_args()</span><br></pre></td></tr></table></figure>

<p>上面涉及到的一些用法：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#x27;-c&#x27;, &#x27;--ckpt&#x27;  表示在命令行使用&#x27;-c&#x27;和&#x27;--ckpt&#x27;都会解析到同一个命令行参数</span><br><span class="line"></span><br><span class="line">default 表示不指定参数时的默认值</span><br><span class="line"></span><br><span class="line">metavar 在 usage说明中的参数名称</span><br><span class="line"></span><br><span class="line">nargs 应该读取的命令行参数个数，可以是具体数字或者？号，当不指定值时对position argument(位置参数)使用</span><br><span class="line">default，对于option argument(选项参数)使用const，使用*号：表示0或多个参数；使用+号，表示1或多个参数，传参时可以用list来表示，如[1,2,3]</span><br><span class="line"></span><br><span class="line">action=&#x27;store_true&#x27; 只要运行时对该变量有传参（就是xx.py --train这样写），就将该变量设为True</span><br><span class="line"></span><br><span class="line">require=True 可选参数不能省略</span><br></pre></td></tr></table></figure>

<p>关于选项参数和位置参数</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">parser.add_argument(&#x27;-c&#x27;, &#x27;--ckpt&#x27;)   # 选项参数</span><br><span class="line">parser.add_argument(&#x27;bar&#x27;)       # 位置参数</span><br><span class="line">位置参数是指命令行参数的顺序必须与定义时候的前后顺序一致，而选项参数可以在命令行中的任意位置指定。一般不用位置参数，不太方便和直观。</span><br></pre></td></tr></table></figure>

<h5 id="pytorch-之-保存和加载ckpt模型"><a href="#pytorch-之-保存和加载ckpt模型" class="headerlink" title="pytorch 之 保存和加载ckpt模型"></a>pytorch 之 保存和加载ckpt模型</h5><p>保存模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(model, <span class="string">&#x27;save.pth&#x27;</span>)  <span class="comment"># 保存整个模型</span></span><br><span class="line">torch.save(model.state_dict(), <span class="string">&#x27;save.pth&#x27;</span>)  <span class="comment"># 只保存训练好的权重</span></span><br></pre></td></tr></table></figure>

<p>加载模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_dict = model.state_dict()   <span class="comment"># 得到一个字典，字典中保存了模型中所有可学习参数的键值对(key: value)</span></span><br><span class="line">model_dict_keys = model_dict.keys()    <span class="comment"># keys()函数以list形式返回一个字典中的所有键</span></span><br><span class="line">model.load_state_dict(model_dict, strict=<span class="literal">True</span>)   <span class="comment"># 加载模型参数，strict=True要求model_dict的关键字必须严格与该模型的state_dict()函数返回的关键字相匹配</span></span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>python编程</tag>
      </tags>
  </entry>
  <entry>
    <title>多模态学习</title>
    <url>/2022/09/01/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>多模态学习：使用机器学习方法对多源异构信息进行挖掘和分析。</p>
]]></content>
      <tags>
        <tag>多模态学习</tag>
      </tags>
  </entry>
  <entry>
    <title>考虑数据不均衡问题的多模态分类</title>
    <url>/2022/12/09/%E8%80%83%E8%99%91%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%9D%87%E8%A1%A1%E9%97%AE%E9%A2%98%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<p>这篇报告是关于考虑数据不均衡问题的多模态分类系统框架介绍。</p>
<h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h3><p>在大数据时代，伴随着多媒体技术的广泛应用和数据描述手段的日渐丰富，多模态数据广泛存在。多模态数据是指对于同一个描述对象，通过不同领域获取到的数据，并且把描述这些数据的每一个领域叫做一个模态。在多模态数据中，每个模态能够为其余模态提供一定的信息，即模态之间存在一定的关联性。所以，在对多模态数据进行数据挖掘与分析时，一个关键的课题是研究多模态数据的融合分析方法。</p>
<p>在实际生活中，存在的一个现象是多模态数据的不均衡问题，一方面是由于数据的<strong>缺失</strong>，另一方面，多模态之间存在主导和次要关系，即<strong>强弱模态问题</strong>。而数据的不均衡可能会导致多模态模型的整体性能劣于单模态，或者在单个模态上的性能劣于单模态。对此，本课题尝试分析由于数据不均衡导致模态性能下降的原因，并提出若干方法来解决问题，从而提升多模态模型的分类等性能。</p>
<ul>
<li><font color=blue>数据不均衡问题：三方面的性质（三类型）</font></li>
</ul>
<p>①类不平衡：比如一个数据集中A类样本量多，B类样本量少  </p>
<p>②模态不平衡：强弱模态（？是否真存在，内在机理是什么）✔</p>
<p>③数据不完整：存在模态缺失的现象  （不研究）</p>
<ul>
<li><font color=blue>多模态融合：显性融合  &amp;  隐性融合</font></li>
</ul>
<p>（1）一些较为朴素的方法如串联融合等</p>
<p>（2）为了有效的跨模态相互作用，Zadeh等人提出了一种<strong>张量融合机制</strong>。在此基础上，又提出了有效的<strong>低秩融合</strong>来解决张量融合的指数维爆炸问题。</p>
<p>上述融合机制在很大程度上依赖于模态的完整性，使得不完全模态数据不可能实现多模态融合。因此，多模态学习的另一个重要方向是建立对模态不完全数据具有鲁棒性的模型。</p>
<p>显式融合需要所有形态的存在。缺失任何一种形式都会破坏训练管道。相比之下，多模态Transformer使用自注意机制来生成所有模态的整体表示，允许缺失某一模态。</p>
<p>（3）Transformer应用于多模态融合</p>
<h3 id="2-方案设计"><a href="#2-方案设计" class="headerlink" title="2. 方案设计"></a>2. 方案设计</h3><p>（1）模态数据的不完整</p>
<p>使用transformer。多模态transformer使用自注意机制生成所有模态的整体表示，因此它允许有模态的缺失。</p>
<p>transformer对缺失模态是如何处理的。（？）</p>
<p>（2）模态存在强弱。主导模态 &amp; 较弱模态</p>
<p>（为什么会存在强弱模态，它的数学机理是什么？）模态的强弱是由于数据特点而决定的，比如语音-视觉模态中，语音模态比视觉模态更能反映该目标本身的特征，在训练时其优化器的优化速度（在显式融合方法中）更快，从而导致另一模态优化器的欠优化。Transformer方法则是一种隐式融合方法（？），</p>
<p>xxxxxxxx整体的方案设计。</p>
<h4 id="2-1-模块一"><a href="#2-1-模块一" class="headerlink" title="2.1 模块一"></a>2.1 模块一</h4><p>动态梯度调制方法OGM-GE；面对模态存在强弱，而导致的单模态优化器训练不够完全的情况，可以用OGM-GE方法改善。</p>
<p>xxxxx</p>
<h4 id="2-2-模块二"><a href="#2-2-模块二" class="headerlink" title="2.2 模块二"></a>2.2 模块二</h4><p>xxxxxx</p>
<h4 id="2-3-损失函数"><a href="#2-3-损失函数" class="headerlink" title="2.3 损失函数"></a>2.3 损失函数</h4><p>xxxxxx</p>
<h3 id="3-数据集介绍"><a href="#3-数据集介绍" class="headerlink" title="3.  数据集介绍"></a>3.  数据集介绍</h3><h4 id="3-1-xxx数据集"><a href="#3-1-xxx数据集" class="headerlink" title="3.1 xxx数据集"></a>3.1 xxx数据集</h4><h4 id="3-2-数据统计和数据探索"><a href="#3-2-数据统计和数据探索" class="headerlink" title="3.2 数据统计和数据探索"></a>3.2 数据统计和数据探索</h4><h4 id="3-3-数据划分"><a href="#3-3-数据划分" class="headerlink" title="3.3 数据划分"></a>3.3 数据划分</h4><p>xxxxx</p>
<h3 id="4-评价指标和对比方法"><a href="#4-评价指标和对比方法" class="headerlink" title="4. 评价指标和对比方法"></a>4. 评价指标和对比方法</h3><h4 id="4-1-评价指标"><a href="#4-1-评价指标" class="headerlink" title="4.1 评价指标"></a>4.1 评价指标</h4><p>xxxx</p>
<h4 id="4-2-对比方法"><a href="#4-2-对比方法" class="headerlink" title="4.2 对比方法"></a>4.2 对比方法</h4><p> xxxx</p>
<h4 id="4-3-消融实验"><a href="#4-3-消融实验" class="headerlink" title="4.3 消融实验"></a>4.3 消融实验</h4><p>xxxxx</p>
<p>参考文献：</p>
<p>[1] Balanced Multimodal Learning via On-the-fly Gradient Modulation. 2022</p>
<p>[2] [2]Low Rank Fusion based Transformers for Multimodal Sequences ( LMF-MulT ) 低秩矩阵融合</p>
<p>[3] Multimodal transformer for unaligned multimodal language sequences ( MulT ) 多模态transformer</p>
]]></content>
      <categories>
        <category>多模态融合</category>
      </categories>
  </entry>
  <entry>
    <title>编程笔记【4.4】</title>
    <url>/2023/04/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0%E3%80%904.4%E3%80%91/</url>
    <content><![CDATA[<h6 id="记录一件奇怪的现象"><a href="#记录一件奇怪的现象" class="headerlink" title="记录一件奇怪的现象"></a>记录一件奇怪的现象</h6><p>我先在卡4上跑了两个epoch，并且把ckpt保存了下来。接着在卡7上继续跑，然后nvidia-smi查看GPU使用情况时发现卡4和卡7上都创建了进程，且是同一个进程号。如果kill -9 PID 则进程被杀死，则我的终端显示python程序结束，并显示：process finished with exit code 137 </p>
<p>请问这是为啥涅？</p>
<p>好家伙，感觉多GPU保存和加载模型时也会有坑需要注意，虽然我还没遇到过，先挖个坑……</p>
<h6 id="小结-深度学习代码编写框架"><a href="#小结-深度学习代码编写框架" class="headerlink" title="小结 深度学习代码编写框架"></a>小结 深度学习代码编写框架</h6><figure class="highlight html"><table><tr><td class="code"><pre><span class="line">-项目名</span><br><span class="line">	-ckpt文件夹（存放各种中间数据）</span><br><span class="line">		-数据集1_模型1</span><br><span class="line">			保存JOSN文件——&gt;存放你的一些配置信息,比如优化器、学习率、批处理大小、...</span><br><span class="line">			保存log.txt——&gt;存放你想在中间过程记录的一些信息，比如每轮结束输出一次xx指标</span><br><span class="line">			保存best_model.pth——&gt;以某种指标存放训练过程中的最佳模型数据</span><br><span class="line">			保存lateset_model.pth——&gt;存放最后一个epoch结束后得到的模型数据</span><br><span class="line">		-数据集2_模型1</span><br><span class="line">		-数据集1_模型2</span><br><span class="line">		-数据集2_模型2</span><br><span class="line">		-...</span><br><span class="line">    -datasets文件夹（存放各种数据集类）</span><br><span class="line">    	-Dataset1.py (里面对Dataset1构建类和方法，用于dataloader调用)</span><br><span class="line">    	-Dataset2.py </span><br><span class="line">    	-...</span><br><span class="line">    -models文件夹 （构造你的模型）	(models这部分的编写不是很固定，按照需求编写即可)</span><br><span class="line">    	-Total_model.py (最后的完整模型，输入是样本数据，输出是整体pipeline的输出)</span><br><span class="line">    	-backbone.py (模型一般有backbone)</span><br><span class="line">    	-modules.py (一些你自己特殊构造的模块/机制)</span><br><span class="line">    	-...</span><br><span class="line">    -utils文件夹</span><br><span class="line">    	-helpers.py (写一些其他的辅助功能函数)</span><br><span class="line">    	-...</span><br><span class="line">    -config.py (配置文件,包括配置数据路径、模型类型、学习率、权重衰减率等超参数)</span><br><span class="line">    -main.py (主函数,实现模型的训练和评估等)</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>python编程</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读《What Makes Training Multi-modal Classification Networks Hard?》</title>
    <url>/2023/03/23/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-OGR-GB/</url>
    <content><![CDATA[<h5 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h5><p>考虑在具有多个输入模态的任务上对多模态网络与单模态网络进行端到端训练：多模态网络接收到更多信息，因此它应该匹配或优于其相应的单模态网络。<font color='pink'>然而，在我们的实验中观察到相反的现象：最好的单模态网络通常优于多模态网络。这一观察结果在模态的不同组合以及视频分类的不同任务和基准之间是一致的。</font>本文认为导致这种结果的原因有两点：①多模态网络的参数量增大，导致模型容易过拟合。②不同模态以不同的速率过拟合和泛化，因此以单一的联合训练策略来训练网络是次优的方案。进而本文针对这两个原因提出了解决方案：Gradient Blending梯度混合。<br>【批注】标红的部分是本文的motivation，即问题的出发点。这里有些瑕疵，是因为这里的融合机制设定<strong>都是后融合，并且是比较简单的后融合方法。</strong>这些融合方法本身可能存在比较大的缺陷。所以这个问题是否成立 还可以在其他融合方法（如前融合、混合融合以及基于模型的融合方法）进行验证。</p>
<h5 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h5><img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230323182214807.png" alt="image-20230323182214807" style="zoom: 50%;" />
图1：不同防止过拟合的方法&不同融合方法

<p>上图：RGB是最佳的单模态网络<br>late-concat是Audio+RGB双模态基于(后)串联融合的方法（即多模态网络使用与单模态相同的架构，在预测之前的最后一层连接后期融合）<br>这种下降的现象在不同的模态组合和不同的betchmark数据集上都存在，如下图（这里只展示了一个数据集Kinetics上的结果）：<br>                                      <img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230323182820165.png" alt="image-20230323182820165" style="zoom:50%;" /><br>而针对这种现象，容易想到的原因有两个：①是由于后融合操作使得模型容量增大，从而导致过拟合造成的；②是由于late-concat这种融合方法欠佳导致的。针对这两个原因，作者先进行了实验，结果如图1所示。只有dropout和mid-concat相比于单模态RGB有一点提升。</p>
<h6 id="不同的融合机制"><a href="#不同的融合机制" class="headerlink" title="不同的融合机制"></a>不同的融合机制</h6><p>这里作者希望说明，出现模型性能下降的原因不是由于late-concat导致的，或者说模型性能下降的现象在多种融合方法上都存在。文中在4种融合机制上进行了实验。</p>
<table>
<thead>
<tr>
<th>融合方法</th>
<th>模型图</th>
<th>模型机制</th>
<th>实验准确度</th>
</tr>
</thead>
<tbody><tr>
<td>late-concat</td>
<td><img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230323185223847.png" alt="image-20230323185223847" style="zoom: 33%;" /></td>
<td>先分别通过单模态网络抽取特征，完成后将特征直接串联，经过一个全连接层映射到同一空间，得到融合特征。</td>
<td>71.4</td>
</tr>
<tr>
<td>mid-concat</td>
<td><img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230323190149854.png" alt="image-20230323190149854" style="zoom:33%;" /></td>
<td>中间串联&#x2F;中间融合&#x2F;前融合。先经过浅层网络提取浅层特征，再将浅层特征串联，再输入到若干层网络</td>
<td>72.8</td>
</tr>
<tr>
<td>SE-gate</td>
<td></td>
<td>一种Gate机制</td>
<td>71.4</td>
</tr>
<tr>
<td>NL-gate</td>
<td></td>
<td>一种Gate机制</td>
<td>72</td>
</tr>
</tbody></table>
<h6 id="不同的解决过拟合的常用方法"><a href="#不同的解决过拟合的常用方法" class="headerlink" title="不同的解决过拟合的常用方法"></a>不同的解决过拟合的常用方法</h6><p>如果使用这些解决过拟合的策略并不能带来模型性能的提升，那么证明多模态模型性能下降的原因不是因为过拟合？这里作者观察到 dropout 和 mid-concat（与 late-concat 相比，参数减少了 37%）比 lateconcat 提高了 1.5% 和 1.4%，这证实了后期concat 的过度拟合问题。<font color='pink'>（那么另外两种方法：pretrain和early-stop为什么不起作用呢。这两种没有改变网络参数量？）</font></p>
<h6 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h6><p>一个感受：比如为什么在2022年阅读一篇2020年的文章时，会被其中引用的2018年的文章所吸引，2018年的那篇被引用的文章大概率质量比较高。这是因为经过了时间的烤盐啊……</p>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
  </entry>
  <entry>
    <title>预推免面试准备</title>
    <url>/2022/08/16/%E9%A2%84%E6%8E%A8%E5%85%8D%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/</url>
    <content><![CDATA[<h2 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0. 写在前面"></a>0. 写在前面</h2><p>准备思路：</p>
<ol>
<li>从自我介绍、科研经历、竞赛项目经历和未来研究兴趣几个方面进行思考和梳理。前后具有逻辑性：基本情况–&gt;本科基础、经历–&gt;兴趣、优势–&gt;读研规划。</li>
<li>对应准备一下英文版。</li>
<li>突出自己的重点、亮点。</li>
</ol>
<h2 id="1-自我介绍"><a href="#1-自我介绍" class="headerlink" title="1. 自我介绍"></a>1. 自我介绍</h2><p>​		中文版3分钟<br>​		英文版3分钟<br>​		中文版1分钟<br>​		英文版1分钟</p>
<p>​		Good morning, dear professor. It’s great honor to be here for the interview. My name is LiRuoxuan. Born in Hubei province, I feel lucky that I can finish my undergraduate education in Nanjing University of Science and Technology, from where I learned a lot. </p>
<p>​		Over the last three years, I was mainly concentrating on obtaining knowledge. Not only from books, but also from discipline competitions, community activities and countless others. learn to be with others and learn to how to learn. I try to improve myself under the direction of UNESCO. From my perspective, integrated development is crucial. I learned to build a sense of responsibility and I furthered my organizing capacity. Moreover, I devoted some time doing research in a group. Though we didn’t get significant achievement, the process led a way for me to pause, to look, to examine, to consider different aspects of a problem, and finally to figure out a solution without pursuing quick success and instant benefits. Further more, I did some part-time jobs which make me feel more confident and cheerful. </p>
<p>By doing all these above, I learned how to manage time. Although I have grasped the basic knowledge of my major, I admit that there is still a long way to go before I can undertake more demanding tasks or researching works, for my knowledge and ability is somewhat limited. So I believe further study is urgent for me .The major that I wish to pursue for my further education is intelligent perception and intelligent computing（智能感知与智能计算）. I plan to concentrate on study and research in this field in my graduate time. And I convince that I can form a systematic view of intelligent perception and intelligent computing, and make a solid foundation for future profession after three years study here! Thank you very much for your time!</p>
<h2 id="2-科研经历"><a href="#2-科研经历" class="headerlink" title="2. 科研经历"></a>2. 科研经历</h2><h2 id="3-项目问答"><a href="#3-项目问答" class="headerlink" title="3. 项目问答"></a>3. 项目问答</h2><h2 id="4-研究兴趣-amp-未来计划"><a href="#4-研究兴趣-amp-未来计划" class="headerlink" title="4. 研究兴趣 &amp; 未来计划"></a>4. 研究兴趣 &amp; 未来计划</h2><h2 id="5-常见提问（中英文版）"><a href="#5-常见提问（中英文版）" class="headerlink" title="5. 常见提问（中英文版）"></a>5. 常见提问（中英文版）</h2><h5 id="1-Introduce-yourself（1min-x2F-3min）"><a href="#1-Introduce-yourself（1min-x2F-3min）" class="headerlink" title="1. Introduce yourself（1min&#x2F;3min）"></a>1. Introduce yourself（1min&#x2F;3min）</h5><p>内容上，包括姓名、年龄、本科院校、专业，想去该校读研的原因，喜欢的研究方向以及自己学习这个方向的基础和优势，结束语句表达憧憬及感谢老师。</p>
<h5 id="2-Why-do-you-choose-A-University？（想来我校读研的原因）"><a href="#2-Why-do-you-choose-A-University？（想来我校读研的原因）" class="headerlink" title="2. Why do you choose A University？（想来我校读研的原因）"></a>2. Why do you choose A University？（想来我校读研的原因）</h5><p>Southeast University（东南大学）</p>
<h5 id="3-What’s-your-major-why-do-you-choose-it-and-what-do-you-think-of-it-（你所学专业，以及为何选择申请这个专业）"><a href="#3-What’s-your-major-why-do-you-choose-it-and-what-do-you-think-of-it-（你所学专业，以及为何选择申请这个专业）" class="headerlink" title="3. What’s your major,why do you choose it and what do you think of it?（你所学专业，以及为何选择申请这个专业）"></a>3. What’s your major,why do you choose it and what do you think of it?（你所学专业，以及为何选择申请这个专业）</h5><p>说一下自己学习这个专业方向的基础和优势，包括为此所作的准备等。</p>
<h5 id="4-What’s-your-plan-for-the-after-3-x2F-5-years-（未来计划）"><a href="#4-What’s-your-plan-for-the-after-3-x2F-5-years-（未来计划）" class="headerlink" title="4. What’s your plan for the after 3&#x2F;5 years?（未来计划）"></a>4. What’s your plan for the after 3&#x2F;5 years?（未来计划）</h5><p>未来研究方向包括大数据分析、强化学习、无人系统、物联网智能感知、多智能体系统、博弈理论等，培养学生用算法与优化方法解决应用问题的能力。</p>
<h5 id="5-Briefly-describe-your-scientific-research-experience-in-English（用英文简述科研经历）"><a href="#5-Briefly-describe-your-scientific-research-experience-in-English（用英文简述科研经历）" class="headerlink" title="5. Briefly describe your scientific research experience in English（用英文简述科研经历）"></a>5. Briefly describe your scientific research experience in English（用英文简述科研经历）</h5><h5 id="6-科研训练读过哪些期刊的相关论文？"><a href="#6-科研训练读过哪些期刊的相关论文？" class="headerlink" title="6. 科研训练读过哪些期刊的相关论文？"></a>6. 科研训练读过哪些期刊的相关论文？</h5><h5 id="7-读过什么专业类书"><a href="#7-读过什么专业类书" class="headerlink" title="7. 读过什么专业类书"></a>7. 读过什么专业类书</h5><h5 id="8-Tell-me-about-your-university（本科学校）"><a href="#8-Tell-me-about-your-university（本科学校）" class="headerlink" title="8. Tell me about your university（本科学校）"></a>8. Tell me about your university（本科学校）</h5><h5 id="9-Tell-me-about-your-hometown（家乡）"><a href="#9-Tell-me-about-your-hometown（家乡）" class="headerlink" title="9. Tell me about your hometown（家乡）"></a>9. Tell me about your hometown（家乡）</h5><h5 id="10-Tell-me-about-your-family（家庭）"><a href="#10-Tell-me-about-your-family（家庭）" class="headerlink" title="10. Tell me about your family（家庭）"></a>10. Tell me about your family（家庭）</h5><h5 id="11-优缺点"><a href="#11-优缺点" class="headerlink" title="11. 优缺点"></a>11. 优缺点</h5><h5 id="12-最喜欢的课程是哪门，简要介绍一下"><a href="#12-最喜欢的课程是哪门，简要介绍一下" class="headerlink" title="12. 最喜欢的课程是哪门，简要介绍一下"></a>12. 最喜欢的课程是哪门，简要介绍一下</h5><h5 id="13-本科有没有担任什么职务"><a href="#13-本科有没有担任什么职务" class="headerlink" title="13. 本科有没有担任什么职务"></a>13. 本科有没有担任什么职务</h5><h5 id="问题没听清-amp-听不懂时"><a href="#问题没听清-amp-听不懂时" class="headerlink" title="问题没听清&amp;听不懂时"></a>问题没听清&amp;听不懂时</h5><p>Sorry, I can’t follow you.<br>Sorry, I lost you. Can you repeat that question again?</p>
<p>Could you please make the question simpler?<br>Could you please express in a different way?</p>
<h2 id="6-专业基础知识"><a href="#6-专业基础知识" class="headerlink" title="6. 专业基础知识"></a>6. 专业基础知识</h2><p>英文描述快速排序过程以及最好最坏复杂度</p>
<p>数据库bc范式和第三范式区别</p>
<p>特征值和特征向量的意义以及之间的关系</p>
<p>TCP-IP的工作过程描述</p>
<p>在局域网中TCP-IP协议栈是否冗余</p>
<p>列举各种排序算法以及复杂度</p>
<p>数据结构快排的优缺点，怎样改进缺点</p>
<p>栈和队列的区别</p>
<p>如何用两个栈实现队列</p>
<p>很简单的双指针，把负数移到正数前。控制到On复杂度</p>
<p>Floyd(菜鸡用了复杂度比较高的方法)</p>
<p>很简单的动态规划</p>
<p>询问什么情况下要使用动态规划？</p>
<p>TCP和UDP之间的区别</p>
<p>解释什么是中心极限定理</p>
<p>C++虚函数的原理</p>
<p>你科研训练中用到的算法以及对科研项目其他的算法是否有了解？</p>
<p>怎样快速找到数组中第k大的数？</p>
<p>讲讲你在数学建模中是如何处理数据的？</p>
<ol>
<li>操作系统</li>
</ol>
<p>（1）磁盘，空闲空间的管理方案和磁盘的存储等一些计算。</p>
<p>（2）页式管理，页号的计算、物理和逻辑存储地址几位，以及访问快表时的命中率为N时，时间为多少.</p>
<p>（3）处理器调度问题，涉及优先级调度，最短作业调度，时间片轮转，用甘特图表示出来，需要注意的是cpu的数量，我做的题目是两个CPU；</p>
<ol start="2">
<li>数据结构（主要是各个算法的思想）</li>
</ol>
<p>（1）归并排序，内部排序（排序方法在内存中进行），外排序为什么不用多路归并。</p>
<p>（2）AVL平衡树旋转，从一个状态插入、删除一个数时，最多旋转几次。</p>
<p>（3）二叉树，证明二度节点数与零度节点数的关系。</p>
<p>（4）回文链，设计一个算法证明一个链时回文链，使得时间复杂度为O(n)空间复杂度为O(1)。</p>
<p>（5）最短路径算法，具体实现中的细节小问题。</p>
<h2 id="7-专业术语（英文）"><a href="#7-专业术语（英文）" class="headerlink" title="7. 专业术语（英文）"></a>7. 专业术语（英文）</h2>]]></content>
      <categories>
        <category>上岸之旅</category>
      </categories>
      <tags>
        <tag>保研面试</tag>
      </tags>
  </entry>
</search>
