<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Encoder-Decoder详解及其数学本质</title>
    <url>/2022/12/04/Encoder-Decoder%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%85%B6%E6%95%B0%E5%AD%A6%E6%9C%AC%E8%B4%A8/</url>
    <content><![CDATA[<h5 id="前言：encoder-decoder-也即-编码器-解码器-结构，它属于一种抽象性的结构，并不表示某一具体结构，在下文可以看到有许多机器学习算法都服从这一结构。"><a href="#前言：encoder-decoder-也即-编码器-解码器-结构，它属于一种抽象性的结构，并不表示某一具体结构，在下文可以看到有许多机器学习算法都服从这一结构。" class="headerlink" title="前言：encoder-decoder 也即 编码器-解码器 结构，它属于一种抽象性的结构，并不表示某一具体结构，在下文可以看到有许多机器学习算法都服从这一结构。"></a>前言：encoder-decoder 也即 编码器-解码器 结构，它属于一种抽象性的结构，并不表示某一具体结构，在下文可以看到有许多机器学习算法都服从这一结构。</h5><h5 id="引入："><a href="#引入：" class="headerlink" title="引入："></a>引入：</h5><p>在机器学习中，很多问题可以抽象出类似的模型：</p>
<ul>
<li>机器翻译。将一种语言的句子转化成另外一种语言的句子。</li>
<li>自动摘要。为一段文字提取出摘要。</li>
<li>为图像生成文字解说。将图像数据转化成文字数据。</li>
<li>根据一段文字描述生成图像。这是上面问题的反过程，将文字转化成图像。</li>
</ul>
<p>其它的例子我们就不一一列举。在这些问题中，我们需要将输入数据转化成另外一种输出数据，<font color=blue><strong>二者之间有概率关系</strong></font>。例如，对于机器翻译来说，二者有相同的语义。</p>
<p>但是，这些情况下直接用一个函数完成这个转化 y&#x3D;f(x)可能会存在困难。例如对机器翻译来说<font color=blue>输入和输出的长度是不固定的</font>，二者还可能不相等。因此我们需要先将输入数据x转化成一种中间数据z，再从z映射出y。这就是编码器-解码器结构。（不固定x——固定z——不固定y）</p>
<h3 id="从PCA说起"><a href="#从PCA说起" class="headerlink" title="从PCA说起"></a>从PCA说起</h3><p>主成分分析是一种经典的无监督数据降维算法。它将一个高维的向量x映射成一个低维的向量y，前提条件是y很好的保留了x的主要信息。在做数据降维时，我们执行如下变换：$$y&#x3D;W(x-m)$$。计算过程很简单，先减掉均值向量，然后左乘投影矩阵即可。其中m是样本集的均值向量，W是投影矩阵，通过样本集计算得到，具体的原理可以参考$$PCA$$的教程。这一投影过程的作用类似于编码器，将高维向量x编码成低维向量y。</p>
<p>有些时候，我们需要从降维后的向量y重构出原始的向量x，这可以通过数据重构算法实现，重构变换方法即$$W^Ty+m$$，这刚好和投影算法相反，是先左乘投影矩阵W的转置， 然后加上均值向量。在这里，重构算法可以看作是解码器，从降维后的向量解码出原始的信号。</p>
<h3 id="自动编码器-Auto-Encoder"><a href="#自动编码器-Auto-Encoder" class="headerlink" title="自动编码器 Auto Encoder"></a>自动编码器 Auto Encoder</h3><p>自动编码器（Auto-Encoder，简称AE）是一种特殊的神经网络，用于特征提取和数据降维。最简单的自动编码器由一个输入层，一个隐含层，一个输出层组成。隐含层的映射充当编码器，输出层的映射充当解码器。</p>
<p>训练时编码器对输入向量进行映射，得到编码后的向量；解码器对编码向量进行映射，得到重构后的向量，它是对输入向量的近似。编码器和解码器同时训练，训练的目标是最小化重构误差，即让重构向量与原始输入向量之间的误差最小化，这与PCA非常类似。因此样本x的标签值就是样本自身。</p>
<p>训练完成之后，在预测时只使用编码器而不再需要解码器，编码器的输出结果被进一步使用，用于分类，回个等任务。</p>
]]></content>
  </entry>
  <entry>
    <title>.sh脚本编写</title>
    <url>/2023/03/22/sh%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99/</url>
    <content><![CDATA[<p>linux下用.sh文件执行python命令</p>
<p>假设要在终端执行的命令是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure>

<p>首先，在执行目录下创建run.sh文件，并在run.sh文件中写入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure>

<p>并保存。</p>
<p>假设train.py是可以输入参数的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python train.py --train --epoches 5</span><br></pre></td></tr></table></figure>

<p>以上命令代表让模型训练，并且训练5轮。于是，在.sh文件中这样写</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python train.py --train --epoches 5</span><br></pre></td></tr></table></figure>

<p>并保存。</p>
<p>假如你希望这个命令执行10次，那么在.sh文件中这样写</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> 1 2 3 4 5 6 7 8 9 10</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">	python train.py --train --epoches 5</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<p>编写好shell文件后，下面是如何在Windows+pycharm环境下使用pycharm运行shell文件</p>
<p>①首先在本机上安装git，并测试git是否安装成功。</p>
<p>测试方法是：右键点击桌面，如果出现“git bash here”等选项，说明安装成功。</p>
<img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230322123825585.png" alt="image-20230322123825585" style="zoom:50%;" />

<p>②设置pycharm的terminal</p>
<p>点击file——settings——tools——terminal——shell path，将cmd.exe改成刚刚下载的git路径。注意选择的路径是sh.exe，不是git.exe</p>
<img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230322124708085.png" alt="image-20230322124708085" style="zoom:80%;" />
]]></content>
      <tags>
        <tag>linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo插入图片</title>
    <url>/2023/03/22/hexo%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87/</url>
    <content><![CDATA[<h5 id="hexo博客插入图片"><a href="#hexo博客插入图片" class="headerlink" title="hexo博客插入图片"></a>hexo博客插入图片</h5><p><a href="https://blog.csdn.net/m0_43401436/article/details/107191688">hexo博客中插入图片失败——解决思路及个人最终解决办法_hexo 出现重复路径_金牛大王的博客-CSDN博客</a></p>
]]></content>
      <tags>
        <tag>hexo博客帮助文档</tag>
      </tags>
  </entry>
  <entry>
    <title>多模态学习</title>
    <url>/2022/09/01/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>多模态学习：使用机器学习方法对多源异构信息进行挖掘和分析。</p>
]]></content>
      <tags>
        <tag>多模态学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文阅读】Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning</title>
    <url>/2023/09/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Mind-the-Gap-Understanding-the-Modality-Gap-in-Multi-modal-Contrastive-Representation-Learning/</url>
    <content><![CDATA[<p>Q1：研究的问题是什么？</p>
<p>提出了模态间的gap现象，以及从数学上证明了contraction mapping(由ReLU引起的收缩映射) 对其的贡献。作者提出下一步的研究的方向是系统地分析gap对下游任务的影响。</p>
]]></content>
      <tags>
        <tag>读论文</tag>
      </tags>
  </entry>
  <entry>
    <title>摘抄录</title>
    <url>/2022/10/04/%E6%91%98%E6%8A%84%E5%BD%95/</url>
    <content><![CDATA[<p>万家墨面没蒿莱，敢有歌吟动地哀。心事浩茫连广宇，于无声处听惊雷。<br>——鲁迅《无题·万家墨面没蒿莱》<br>译文：黎民百姓们像黑瘦的囚徒，流离失所于荒野，哪还敢有慷慨悲歌，引发动地的哀声。我心里想的事很多、很远，连通着广大国土上的人民，所以从表面沉寂中，我能听到革命春雷的萌动。</p>
<p>​        我们自古以来，就有埋头苦干的人，有拼命硬干的人，有为民请命的人，有舍身求法的人，……虽是等于为帝王将相作家谱的所谓“正史”，也往往掩不住他们的光耀，这就是中国的脊梁。<br>​        这一类的人们，就是现在也何尝少呢？他们有确信，不自欺；他们在前仆后继地战斗，不过一面总在被摧残，被抹杀，消灭于黑暗中，不能为大家所知道罢了。说中国人失掉自信力，用于指一部分人则可，倘若加于全体，那简直是污蔑。<br>​        要论中国人，必须不被搽在表面的自欺欺人的脂粉所诓骗，却看看他的筋骨和脊梁。自信力的有无，状元宰相的文章是不足为据的，要自己去看地底下。<br>——鲁迅《中国人失掉自信力了吗？》</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2023/04/17/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0-Pytorch%20%E4%B9%8B%E6%A2%AF%E5%BA%A6%E5%9B%9E%E4%BC%A0%20%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/</url>
    <content><![CDATA[<p>Pytorch 之梯度回传 实现细节</p>
<h5 id="首先厘清几个重要概念："><a href="#首先厘清几个重要概念：" class="headerlink" title="首先厘清几个重要概念："></a>首先厘清几个重要概念：</h5><ul>
<li><p>criterion </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()   <span class="comment"># 交叉熵损失函数</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>model</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = AVClassifier()  <span class="comment"># 创建我们需要的模型  AVClassifier继承nn.Module类</span></span><br><span class="line">model.apply(weight_init)   <span class="comment"># 对模型的参数做初始化</span></span><br><span class="line">model.train()   <span class="comment"># 将模型调到训练状态   # 还有对应的测试状态：model.eval()</span></span><br><span class="line">......</span><br></pre></td></tr></table></figure>
</li>
<li><p>optimizer</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">1e-3</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">1e-4</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>loss</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">out = model(imagedata, textdata)</span><br><span class="line">loss = criterion(out, label)   # loss是计算得到的损失值</span><br></pre></td></tr></table></figure></li>
</ul>
<h5 id="一般传统的回传步骤如下："><a href="#一般传统的回传步骤如下：" class="headerlink" title="一般传统的回传步骤如下："></a>一般传统的回传步骤如下：</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先定义好了criterion、model、optimizer</span></span><br><span class="line">model = AVClassifier() </span><br><span class="line">model.apply(weight_init)</span><br><span class="line">model.train()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">1e-3</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">1e-4</span>)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 在一个epoch里面，开始按照batchsize取出训练集中的数据batch</span></span><br><span class="line"><span class="keyword">for</span> step, (img, text, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">	optimizer.zero_grad()   <span class="comment"># 清除过往的所有梯度值，置为零</span></span><br><span class="line">    output = model(img, text)   <span class="comment"># 前向传播求出预测值</span></span><br><span class="line">    loss = criterion(output, label)  <span class="comment"># 根据预测值和标签计算相应的损失函数值</span></span><br><span class="line">    loss.backward()   <span class="comment"># 根据链式法则求梯度</span></span><br><span class="line">    optimizer.step()  <span class="comment"># 根据SGD算法以及计算得到的梯度更新模型的所有参数</span></span><br></pre></td></tr></table></figure>

<h5 id="现在我们遇到的问题是："><a href="#现在我们遇到的问题是：" class="headerlink" title="现在我们遇到的问题是："></a>现在我们遇到的问题是：</h5><p>我们使用pytorch写好了基本的model框架，现在我们想加入一个AF模块。</p>
<p>原来的model基本架构如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AVClassifier</span>(nn.Module):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">		self.img_encoder = ImgEncoder()</span><br><span class="line">        self.text_encoder = TextEncoder()</span><br><span class="line">        self.fusion_module = ConcatFusion()</span><br><span class="line">        self.Classifier = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">            nn.softmax(dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img, text</span>):</span><br><span class="line">        img_feature = self.img_encoder(img)</span><br><span class="line">        text_feature = self.text_encoder(text)</span><br><span class="line">        out = self.fusion_module(img_feature, text_feature)</span><br><span class="line">        output = self.classifier(out)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<p>现在我想在Encoder和fusion_module中间增加一个AF模块，AF模块主要实现的功能是捕捉特征之间的关联信息，分两步走：第一步做feature boosting，第二步将计算一个关系融合矩阵，再将feature boosting得到的特征乘以特定的系数，并与关系融合矩阵做矩阵乘法，得到AF加强后的特征。我们希望将通过AF的模块再放入融合模块，继续后续的步骤。</p>
<p>我是这样写的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AVClassifier</span>(nn.Module):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">		self.img_encoder = ImgEncoder()</span><br><span class="line">        self.text_encoder = TextEncoder()</span><br><span class="line">        self.fusion_module = ConcatFusion()</span><br><span class="line">        self.Classifier = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">            nn.softmax(dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img, text</span>):</span><br><span class="line">        img_feature = self.img_encoder(img)</span><br><span class="line">        text_feature = self.text_encoder(text)</span><br><span class="line">        <span class="comment"># AF模块的功能我用函数getX_coupled_feas()来实现</span></span><br><span class="line">        img_feature_af = getX_coupled_feas(img_feature)</span><br><span class="line">        text_feature_af = getX_coupled_feas(text_feature)</span><br><span class="line">        out = self.fusion_module(img_feature, text_feature)</span><br><span class="line">        output = self.classifier(out)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<p>这样写的结果是，通过debug调试，我们发现由于增加了AF函数，在反向传播计算梯度时出现了失败。在AF模块后面的融合模块和分类头表现为参数(weight)的梯度值(grad)始终为0，而在AF模块前的两个Encoder模块的模型参数的梯度值始终为None.</p>
<p>关系融合矩阵的每个元素a(i, j)是第i维特征和第j维特征计算皮尔逊相关系数得到的。关系融合矩阵是一个矩阵，并且与特征进行矩阵乘法，那么它从本质意义上来说就是一种映射。但是它的权重(weight)不是通过模型”学习”到的，而是基于一种规则(基于相关系数进行计算)得到的，它的权重不需要根据梯度回传来更新。但是梯度的计算不能到这里就断掉了，因为它前面的encoder模块参数还需要根据梯度来更新啊~这怎么办呢？</p>
<p>一个首先要回答的问题是：增加了AF模块后，根据链式法则，梯度要如何计算？</p>
<p>AF模块：一个进行intra-modal fusion的模块。AF的输入是encoder得到的特征，AF的输出是将要进入fusion_module的特征。</p>
<h5 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h5><p>反向传播（backward propagation）指的是计算神经网络参数梯度的方法。</p>
<p>PS：机器学习中常见的最优化方法：除了梯度下降法之外，还有牛顿法、拟牛顿法、共轭梯度法、启发式优化方法、拉格朗日乘数法。还有一些无梯度神经网络优化方法，比如粒子群优化、替代优化、模拟退火算法。</p>
]]></content>
  </entry>
  <entry>
    <title>基于城市综合环境因子的多维轨道交通客流预测模型</title>
    <url>/2023/05/30/%E5%9F%BA%E4%BA%8E%E5%9F%8E%E5%B8%82%E7%BB%BC%E5%90%88%E7%8E%AF%E5%A2%83%E5%9B%A0%E5%AD%90%E7%9A%84%E5%A4%9A%E7%BB%B4%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A%E5%AE%A2%E6%B5%81%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<ol>
<li><p>客流预测的意义：客流是合理规划运输网络、配置客运站点设施、配备旅客运输工具和编制其运行作业计划的基本依据。</p>
</li>
<li><p>名词解释</p>
</li>
</ol>
<p>1）客流是一定时间内某一运输路线路段上一定方向的旅客流动，包含流量、流向和流时等要素。</p>
<p>2）客流流量：旅客流动的数量 </p>
<p>3）流向：流动的方向</p>
<p>4）流时：指流量的时间分布</p>
<ol start="3">
<li>参考论文</li>
</ol>
<p>《基于乘积ARIMA模型的城市轨道交通进出站客流量预测》</p>
<p>《城市轨道交通客流预测与分析方法》</p>
<p>《城市轨道交通网络网络化客流特征及成长规律—基于京沪穗深城市轨道交通网络客流数据分析》 </p>
<ol start="4">
<li>数据集</li>
</ol>
<p>客流量数据.csv——训练集，包含station&#x2F;time&#x2F;inbound_number&#x2F;outbound_number等数据，但格式不太一样，需要预处理，有23.36w条数据。</p>
<p>test.csv——测试集，包含station&#x2F;time&#x2F;inbound_number&#x2F;outbound_number等数据，有600+条数据。</p>
<p>车站信息表：各站点的关系数据和位置数据，暂无作用。</p>
<ol start="5">
<li>提交结果格式</li>
</ol>
<p>预测客流量.csv文件，预测2023&#x2F;4&#x2F;16这一整天的各个时间段的各个站点（A~G）的客流量</p>
<p>（下方示例）</p>
<table>
<thead>
<tr>
<th>Station</th>
<th>Time</th>
<th>inbound_number</th>
<th>outbound_number</th>
</tr>
</thead>
<tbody><tr>
<td>A</td>
<td>2023&#x2F;4&#x2F;16 6:00</td>
<td>100</td>
<td>200</td>
</tr>
<tr>
<td>B</td>
<td>2023&#x2F;4&#x2F;16 6:00</td>
<td>200</td>
<td>150</td>
</tr>
</tbody></table>
]]></content>
      <tags>
        <tag>算法竞赛</tag>
      </tags>
  </entry>
  <entry>
    <title>编程笔记【4.3】</title>
    <url>/2023/04/03/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0%E3%80%904-3%E3%80%91/</url>
    <content><![CDATA[<h5 id="Python-之-使用argparse模块编写命令行接口"><a href="#Python-之-使用argparse模块编写命令行接口" class="headerlink" title="Python 之 使用argparse模块编写命令行接口"></a>Python 之 使用argparse模块编写命令行接口</h5><p>argparse模块是Python内置的一个用于命令行选项、参数和子命令解析器的模块。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建一个解析器，即一个ArgumentParser对象</span></span><br><span class="line">parser=argparse.ArgumentParser(description=<span class="string">&#x27;Full Pipeline Training&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加参数</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--data_path&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;/path/to/data&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;root dir that contain train data and test data. &#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;--ckpt&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;/path/to/ckpt&#x27;</span>, metavar=<span class="string">&#x27;PATH&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;path to the latest checkpoint (default: model)&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--gpu&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, nargs=<span class="string">&#x27;+&#x27;</span>, default=[<span class="number">6</span>], <span class="built_in">help</span>=<span class="string">&#x27;select gpu. &#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--train&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&#x27;If true, the model will train, else only validate. &#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--alpha&#x27;</span>, require=<span class="literal">True</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;alpha in the modal. &#x27;</span>)</span><br><span class="line"><span class="comment"># 使用</span></span><br><span class="line">args=parser.parse_args()</span><br></pre></td></tr></table></figure>

<p>上面涉及到的一些用法：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#x27;-c&#x27;, &#x27;--ckpt&#x27;  表示在命令行使用&#x27;-c&#x27;和&#x27;--ckpt&#x27;都会解析到同一个命令行参数</span><br><span class="line"></span><br><span class="line">default 表示不指定参数时的默认值</span><br><span class="line"></span><br><span class="line">metavar 在 usage说明中的参数名称</span><br><span class="line"></span><br><span class="line">nargs 应该读取的命令行参数个数，可以是具体数字或者？号，当不指定值时对position argument(位置参数)使用</span><br><span class="line">default，对于option argument(选项参数)使用const，使用*号：表示0或多个参数；使用+号，表示1或多个参数，传参时可以用list来表示，如[1,2,3]</span><br><span class="line"></span><br><span class="line">action=&#x27;store_true&#x27; 只要运行时对该变量有传参（就是xx.py --train这样写），就将该变量设为True</span><br><span class="line"></span><br><span class="line">require=True 可选参数不能省略</span><br></pre></td></tr></table></figure>

<p>关于选项参数和位置参数</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">parser.add_argument(&#x27;-c&#x27;, &#x27;--ckpt&#x27;)   # 选项参数</span><br><span class="line">parser.add_argument(&#x27;bar&#x27;)       # 位置参数</span><br><span class="line">位置参数是指命令行参数的顺序必须与定义时候的前后顺序一致，而选项参数可以在命令行中的任意位置指定。一般不用位置参数，不太方便和直观。</span><br></pre></td></tr></table></figure>

<h5 id="pytorch-之-保存和加载ckpt模型"><a href="#pytorch-之-保存和加载ckpt模型" class="headerlink" title="pytorch 之 保存和加载ckpt模型"></a>pytorch 之 保存和加载ckpt模型</h5><p>保存模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(model, <span class="string">&#x27;save.pth&#x27;</span>)  <span class="comment"># 保存整个模型</span></span><br><span class="line">torch.save(model.state_dict(), <span class="string">&#x27;save.pth&#x27;</span>)  <span class="comment"># 只保存训练好的权重</span></span><br></pre></td></tr></table></figure>

<p>加载模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_dict = model.state_dict()   <span class="comment"># 得到一个字典，字典中保存了模型中所有可学习参数的键值对(key: value)</span></span><br><span class="line">model_dict_keys = model_dict.keys()    <span class="comment"># keys()函数以list形式返回一个字典中的所有键</span></span><br><span class="line">model.load_state_dict(model_dict, strict=<span class="literal">True</span>)   <span class="comment"># 加载模型参数，strict=True要求model_dict的关键字必须严格与该模型的state_dict()函数返回的关键字相匹配</span></span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>python编程</tag>
      </tags>
  </entry>
  <entry>
    <title>编程笔记【4.4】</title>
    <url>/2023/04/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0%E3%80%904.4%E3%80%91/</url>
    <content><![CDATA[<h6 id="记录一件奇怪的现象"><a href="#记录一件奇怪的现象" class="headerlink" title="记录一件奇怪的现象"></a>记录一件奇怪的现象</h6><p>我先在卡4上跑了两个epoch，并且把ckpt保存了下来。接着在卡7上继续跑，然后nvidia-smi查看GPU使用情况时发现卡4和卡7上都创建了进程，且是同一个进程号。如果kill -9 PID 则进程被杀死，则我的终端显示python程序结束，并显示：process finished with exit code 137 </p>
<p>请问这是为啥涅？</p>
<p>好家伙，感觉多GPU保存和加载模型时也会有坑需要注意，虽然我还没遇到过，先挖个坑……</p>
<h6 id="小结-深度学习代码编写框架"><a href="#小结-深度学习代码编写框架" class="headerlink" title="小结 深度学习代码编写框架"></a>小结 深度学习代码编写框架</h6><figure class="highlight html"><table><tr><td class="code"><pre><span class="line">-项目名</span><br><span class="line">	-ckpt文件夹（存放各种中间数据）</span><br><span class="line">		-数据集1_模型1</span><br><span class="line">			保存JOSN文件——&gt;存放你的一些配置信息,比如优化器、学习率、批处理大小、...</span><br><span class="line">			保存log.txt——&gt;存放你想在中间过程记录的一些信息，比如每轮结束输出一次xx指标</span><br><span class="line">			保存best_model.pth——&gt;以某种指标存放训练过程中的最佳模型数据</span><br><span class="line">			保存lateset_model.pth——&gt;存放最后一个epoch结束后得到的模型数据</span><br><span class="line">		-数据集2_模型1</span><br><span class="line">		-数据集1_模型2</span><br><span class="line">		-数据集2_模型2</span><br><span class="line">		-...</span><br><span class="line">    -datasets文件夹（存放各种数据集类）</span><br><span class="line">    	-Dataset1.py (里面对Dataset1构建类和方法，用于dataloader调用)</span><br><span class="line">    	-Dataset2.py </span><br><span class="line">    	-...</span><br><span class="line">    -models文件夹 （构造你的模型）	(models这部分的编写不是很固定，按照需求编写即可)</span><br><span class="line">    	-Total_model.py (最后的完整模型，输入是样本数据，输出是整体pipeline的输出)</span><br><span class="line">    	-backbone.py (模型一般有backbone)</span><br><span class="line">    	-modules.py (一些你自己特殊构造的模块/机制)</span><br><span class="line">    	-...</span><br><span class="line">    -utils文件夹</span><br><span class="line">    	-helpers.py (写一些其他的辅助功能函数)</span><br><span class="line">    	-...</span><br><span class="line">    -config.py (配置文件,包括配置数据路径、模型类型、学习率、权重衰减率等超参数)</span><br><span class="line">    -main.py (主函数,实现模型的训练和评估等)</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>python编程</tag>
      </tags>
  </entry>
  <entry>
    <title>Video类型数据预处理</title>
    <url>/2023/04/08/%E8%A7%86%E9%A2%91%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h6 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h6><p>最近做的多模态动作识别任务，是基于Kinetics数据集进行的，需要从原始的视频数据中提取音频模态的数据用于训练。</p>
<h6 id="基本步骤"><a href="#基本步骤" class="headerlink" title="基本步骤"></a>基本步骤</h6><p>提取audio数据，最后转化为音谱图spectrogram放入卷积神经网络用于训练。</p>
<h6 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h6><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在KSDataset上的定义，这里是定义的__getitem__函数，后续用dataloader取数据</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="comment"># audio</span></span><br><span class="line">        sample, rate = librosa.load(self.audio[idx], sr=<span class="number">35400</span>, mono=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(sample) == <span class="number">0</span>:</span><br><span class="line">            sample = np.array([<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(sample) / rate &lt; <span class="number">10.</span>:</span><br><span class="line">            sample = np.tile(sample, <span class="number">2</span>)</span><br><span class="line">        start_point = <span class="number">0</span></span><br><span class="line">        new_sample = sample[start_point:start_point + rate * <span class="number">10</span>]</span><br><span class="line">        new_sample[new_sample &gt; <span class="number">1.</span>] = <span class="number">1.</span></span><br><span class="line">        new_sample[new_sample &lt; -<span class="number">1.</span>] = -<span class="number">1.</span></span><br><span class="line">        spectrogram = librosa.stft(new_sample, n_fft=<span class="number">512</span>, hop_length=<span class="number">353</span>)</span><br><span class="line">        spectrogram = np.log(np.<span class="built_in">abs</span>(spectrogram) + <span class="number">1e-7</span>)</span><br><span class="line">        spectrogram = np.resize(spectrogram, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">        spectrogram = torch.from_numpy(spectrogram)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">代码解析：</span><br><span class="line">sample, rate = librosa.load(self.audio[idx], sr=35400, mono=True)</span><br><span class="line">函数使用：sample, rate = librosa.load(path, sr, mono)</span><br><span class="line">函数参数：path-音频路径</span><br><span class="line">sr-采样率，默认是22050</span><br><span class="line">mono-设置为True是单通道，否则是双通道</span><br><span class="line">函数返回值：</span><br><span class="line">sample-音频的信号值，类型是ndarray</span><br><span class="line">rate-采样率</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spectrogram = librosa.stft(new_sample, n_fft=512, hop_length=353)</span><br><span class="line">函数使用：</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据预处理</category>
      </categories>
  </entry>
  <entry>
    <title>考虑数据不均衡问题的多模态分类</title>
    <url>/2022/12/09/%E8%80%83%E8%99%91%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%9D%87%E8%A1%A1%E9%97%AE%E9%A2%98%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<p>这篇报告是关于考虑数据不均衡问题的多模态分类系统框架介绍。</p>
<h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h3><p>在大数据时代，伴随着多媒体技术的广泛应用和数据描述手段的日渐丰富，多模态数据广泛存在。多模态数据是指对于同一个描述对象，通过不同领域获取到的数据，并且把描述这些数据的每一个领域叫做一个模态。在多模态数据中，每个模态能够为其余模态提供一定的信息，即模态之间存在一定的关联性。所以，在对多模态数据进行数据挖掘与分析时，一个关键的课题是研究多模态数据的融合分析方法。</p>
<p>在实际生活中，存在的一个现象是多模态数据的不均衡问题，一方面是由于数据的<strong>缺失</strong>，另一方面，多模态之间存在主导和次要关系，即<strong>强弱模态问题</strong>。而数据的不均衡可能会导致多模态模型的整体性能劣于单模态，或者在单个模态上的性能劣于单模态。对此，本课题尝试分析由于数据不均衡导致模态性能下降的原因，并提出若干方法来解决问题，从而提升多模态模型的分类等性能。</p>
<ul>
<li><font color=blue>数据不均衡问题：三方面的性质（三类型）</font></li>
</ul>
<p>①类不平衡：比如一个数据集中A类样本量多，B类样本量少  </p>
<p>②模态不平衡：强弱模态（？是否真存在，内在机理是什么）✔</p>
<p>③数据不完整：存在模态缺失的现象  （不研究）</p>
<ul>
<li><font color=blue>多模态融合：显性融合  &amp;  隐性融合</font></li>
</ul>
<p>（1）一些较为朴素的方法如串联融合等</p>
<p>（2）为了有效的跨模态相互作用，Zadeh等人提出了一种<strong>张量融合机制</strong>。在此基础上，又提出了有效的<strong>低秩融合</strong>来解决张量融合的指数维爆炸问题。</p>
<p>上述融合机制在很大程度上依赖于模态的完整性，使得不完全模态数据不可能实现多模态融合。因此，多模态学习的另一个重要方向是建立对模态不完全数据具有鲁棒性的模型。</p>
<p>显式融合需要所有形态的存在。缺失任何一种形式都会破坏训练管道。相比之下，多模态Transformer使用自注意机制来生成所有模态的整体表示，允许缺失某一模态。</p>
<p>（3）Transformer应用于多模态融合</p>
<h3 id="2-方案设计"><a href="#2-方案设计" class="headerlink" title="2. 方案设计"></a>2. 方案设计</h3><p>（1）模态数据的不完整</p>
<p>使用transformer。多模态transformer使用自注意机制生成所有模态的整体表示，因此它允许有模态的缺失。</p>
<p>transformer对缺失模态是如何处理的。（？）</p>
<p>（2）模态存在强弱。主导模态 &amp; 较弱模态</p>
<p>（为什么会存在强弱模态，它的数学机理是什么？）模态的强弱是由于数据特点而决定的，比如语音-视觉模态中，语音模态比视觉模态更能反映该目标本身的特征，在训练时其优化器的优化速度（在显式融合方法中）更快，从而导致另一模态优化器的欠优化。Transformer方法则是一种隐式融合方法（？），</p>
<p>xxxxxxxx整体的方案设计。</p>
<h4 id="2-1-模块一"><a href="#2-1-模块一" class="headerlink" title="2.1 模块一"></a>2.1 模块一</h4><p>动态梯度调制方法OGM-GE；面对模态存在强弱，而导致的单模态优化器训练不够完全的情况，可以用OGM-GE方法改善。</p>
<p>xxxxx</p>
<h4 id="2-2-模块二"><a href="#2-2-模块二" class="headerlink" title="2.2 模块二"></a>2.2 模块二</h4><p>xxxxxx</p>
<h4 id="2-3-损失函数"><a href="#2-3-损失函数" class="headerlink" title="2.3 损失函数"></a>2.3 损失函数</h4><p>xxxxxx</p>
<h3 id="3-数据集介绍"><a href="#3-数据集介绍" class="headerlink" title="3.  数据集介绍"></a>3.  数据集介绍</h3><h4 id="3-1-xxx数据集"><a href="#3-1-xxx数据集" class="headerlink" title="3.1 xxx数据集"></a>3.1 xxx数据集</h4><h4 id="3-2-数据统计和数据探索"><a href="#3-2-数据统计和数据探索" class="headerlink" title="3.2 数据统计和数据探索"></a>3.2 数据统计和数据探索</h4><h4 id="3-3-数据划分"><a href="#3-3-数据划分" class="headerlink" title="3.3 数据划分"></a>3.3 数据划分</h4><p>xxxxx</p>
<h3 id="4-评价指标和对比方法"><a href="#4-评价指标和对比方法" class="headerlink" title="4. 评价指标和对比方法"></a>4. 评价指标和对比方法</h3><h4 id="4-1-评价指标"><a href="#4-1-评价指标" class="headerlink" title="4.1 评价指标"></a>4.1 评价指标</h4><p>xxxx</p>
<h4 id="4-2-对比方法"><a href="#4-2-对比方法" class="headerlink" title="4.2 对比方法"></a>4.2 对比方法</h4><p> xxxx</p>
<h4 id="4-3-消融实验"><a href="#4-3-消融实验" class="headerlink" title="4.3 消融实验"></a>4.3 消融实验</h4><p>xxxxx</p>
<p>参考文献：</p>
<p>[1] Balanced Multimodal Learning via On-the-fly Gradient Modulation. 2022</p>
<p>[2] [2]Low Rank Fusion based Transformers for Multimodal Sequences ( LMF-MulT ) 低秩矩阵融合</p>
<p>[3] Multimodal transformer for unaligned multimodal language sequences ( MulT ) 多模态transformer</p>
]]></content>
      <categories>
        <category>多模态融合</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读《Learning Modality-Specific Representations with Self-Supervised Multi-Task Learning for Multimodal Sentiment Analysis》</title>
    <url>/2023/04/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Self-MM/</url>
    <content><![CDATA[<h5 id="2-related-work"><a href="#2-related-work" class="headerlink" title="2. related work"></a>2. related work</h5><h6 id="2-1-Multimodal-Sentiment-Analysis-MSA"><a href="#2-1-Multimodal-Sentiment-Analysis-MSA" class="headerlink" title="2.1 Multimodal Sentiment Analysis (MSA)"></a>2.1 Multimodal Sentiment Analysis (MSA)</h6><p>MSA 已经成为整合语言和非语言信息（如视觉和声学）的重要研究课题。以前的研究人员主要关注表示学习方法和多模态融合方法。</p>
<table>
<thead>
<tr>
<th>方法类别</th>
<th>论文</th>
<th>基本思路</th>
</tr>
</thead>
<tbody><tr>
<td>表示学习方法</td>
<td>Words can shift: Dynamically adjusting word representations using nonverbal behaviors.<br />AAAI2019</td>
<td>construct a recurrent attended variation embedding network to generate multimodal shifting<br />构建了一个循环参与的变化嵌入网络来生成多模态移动。</td>
</tr>
<tr>
<td>表示学习方法</td>
<td>MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis<br />ACMMM 2020</td>
<td>present modality-invariant and modality-specific representations for representation learning in multimodal.<br />提出了多模态表示学习的模态不变和模态特定表示</td>
</tr>
<tr>
<td>多模态融合-早期融合<br />（早期融合方法通常使用精细的注意机制进行跨模态融合）</td>
<td>Memory fusion network for multi-view sequential learning.<br />AAAI 2018</td>
<td>design a memory fusion network for cross-view interactions.<br />设计了一种用于跨视图交互的内存融合网络</td>
</tr>
<tr>
<td>多模态融合-早期融合</td>
<td>Multimodal transformer for unaligned multimodal language sequences.<br />ACL 2019</td>
<td>propose cross-modal transformers, which learn the cross-modal attention to reinforce a target modality.<br />提出了跨模态变压器，它学习跨模态注意来加强目标模态。</td>
</tr>
<tr>
<td>多模态融合-后期融合<br />(后期融合方法首先学习模态内表示，最后进行多模态融合)</td>
<td>Tensor fusion network for multimodal sentiment analysis.<br />EMNLP 2017</td>
<td>use a tensor fusion network that obtains tensor representation by computing the outer product between unimodal representations<br />使用张量融合网络，通过计算单峰表示之间的外积来获得张量表示</td>
</tr>
<tr>
<td>多模态融合-后期融合</td>
<td>Efficient Low-rank Multimodal Fusion With Modality-Specific Factors.<br />ACL 2018</td>
<td>propose a lowrank multimodal fusion method to decrease the computational complexity of tensor-based methods.<br />提出了一种低秩多模态融合方法来降低基于张量的方法的计算复杂度</td>
</tr>
</tbody></table>
<p>这篇文章主要研究基于后期融合结构的表示学习。与以往研究不同，本文通过自监督策略联合学习单模态和多模态任务。主方法从多模态任务中学习相似性信息，并从单模态任务中学习差异性信息。</p>
<h5 id="2-3-Multi-Task-learning"><a href="#2-3-Multi-Task-learning" class="headerlink" title="2.3 Multi-Task learning"></a>2.3 Multi-Task learning</h5><p>多任务学习旨在通过利用不同任务中包含的知识来提高多个相关任务的泛化性能（多任务综述[[1]](#paper 1)）。与单任务学习相比，训练阶段多任务学习有两个主要挑战。第一个是如何共享网络参数，包括<strong>硬共享和软共享方法</strong>。第二个是如何平衡不同任务的学习过程。使用多任务学习来解决MSA问题的最近工作有[[2]](#paper 2)</p>
<p>在本文的工作中，引入了单模态子任务来帮助特定于模态的表示学习。本文采用了硬共享策略，设计了一种权重调整方法来解决如何平衡的问题。</p>
<h5 id="3-Methodology"><a href="#3-Methodology" class="headerlink" title="3. Methodology"></a>3. Methodology</h5><p> 明日计划：</p>
<p>阅读 SelfMM 论文 + 代码复现在CREMAD上</p>
<p>MISA  Self-MM CH-SIMS  (MMSA框架)   是同一个实验室的工作</p>
<p>参考文献：</p>
<p><a name="paper 1">[1]</a> A Survey on Multi-Task Learning. </p>
<p>[2] CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotation of Modality. </p>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读《What Makes Training Multi-modal Classification Networks Hard?》</title>
    <url>/2023/03/23/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-OGR-GB/</url>
    <content><![CDATA[<h5 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h5><p>考虑在具有多个输入模态的任务上对多模态网络与单模态网络进行端到端训练：多模态网络接收到更多信息，因此它应该匹配或优于其相应的单模态网络。<font color='pink'>然而，在我们的实验中观察到相反的现象：最好的单模态网络通常优于多模态网络。这一观察结果在模态的不同组合以及视频分类的不同任务和基准之间是一致的。</font>本文认为导致这种结果的原因有两点：①多模态网络的参数量增大，导致模型容易过拟合。②不同模态以不同的速率过拟合和泛化，因此以单一的联合训练策略来训练网络是次优的方案。进而本文针对这两个原因提出了解决方案：Gradient Blending梯度混合。<br>【批注】标红的部分是本文的motivation，即问题的出发点。这里有些瑕疵，是因为这里的融合机制设定<strong>都是后融合，并且是比较简单的后融合方法。</strong>这些融合方法本身可能存在比较大的缺陷。所以这个问题是否成立 还可以在其他融合方法（如前融合、混合融合以及基于模型的融合方法）进行验证。</p>
<h5 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h5><img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230323182214807.png" alt="image-20230323182214807" style="zoom: 50%;" />
图1：不同防止过拟合的方法&不同融合方法

<p>上图：RGB是最佳的单模态网络<br>late-concat是Audio+RGB双模态基于(后)串联融合的方法（即多模态网络使用与单模态相同的架构，在预测之前的最后一层连接后期融合）<br>这种下降的现象在不同的模态组合和不同的betchmark数据集上都存在，如下图（这里只展示了一个数据集Kinetics上的结果）：<br>                                      <img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230323182820165.png" alt="image-20230323182820165" style="zoom:50%;" /><br>而针对这种现象，容易想到的原因有两个：①是由于后融合操作使得模型容量增大，从而导致过拟合造成的；②是由于late-concat这种融合方法欠佳导致的。针对这两个原因，作者先进行了实验，结果如图1所示。只有dropout和mid-concat相比于单模态RGB有一点提升。</p>
<h6 id="不同的融合机制"><a href="#不同的融合机制" class="headerlink" title="不同的融合机制"></a>不同的融合机制</h6><p>这里作者希望说明，出现模型性能下降的原因不是由于late-concat导致的，或者说模型性能下降的现象在多种融合方法上都存在。文中在4种融合机制上进行了实验。</p>
<table>
<thead>
<tr>
<th>融合方法</th>
<th>模型图</th>
<th>模型机制</th>
<th>实验准确度</th>
</tr>
</thead>
<tbody><tr>
<td>late-concat</td>
<td><img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230323185223847.png" alt="image-20230323185223847" style="zoom: 33%;" /></td>
<td>先分别通过单模态网络抽取特征，完成后将特征直接串联，经过一个全连接层映射到同一空间，得到融合特征。</td>
<td>71.4</td>
</tr>
<tr>
<td>mid-concat</td>
<td><img src="C:\Users\xuan\AppData\Roaming\Typora\typora-user-images\image-20230323190149854.png" alt="image-20230323190149854" style="zoom:33%;" /></td>
<td>中间串联&#x2F;中间融合&#x2F;前融合。先经过浅层网络提取浅层特征，再将浅层特征串联，再输入到若干层网络</td>
<td>72.8</td>
</tr>
<tr>
<td>SE-gate</td>
<td></td>
<td>一种Gate机制</td>
<td>71.4</td>
</tr>
<tr>
<td>NL-gate</td>
<td></td>
<td>一种Gate机制</td>
<td>72</td>
</tr>
</tbody></table>
<h6 id="不同的解决过拟合的常用方法"><a href="#不同的解决过拟合的常用方法" class="headerlink" title="不同的解决过拟合的常用方法"></a>不同的解决过拟合的常用方法</h6><p>如果使用这些解决过拟合的策略并不能带来模型性能的提升，那么证明多模态模型性能下降的原因不是因为过拟合？这里作者观察到 dropout 和 mid-concat（与 late-concat 相比，参数减少了 37%）比 lateconcat 提高了 1.5% 和 1.4%，这证实了后期concat 的过度拟合问题。<font color='pink'>（那么另外两种方法：pretrain和early-stop为什么不起作用呢。这两种没有改变网络参数量？）</font></p>
<h6 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h6><p>一个感受：比如为什么在2022年阅读一篇2020年的文章时，会被其中引用的2018年的文章所吸引，2018年的那篇被引用的文章大概率质量比较高。这是因为经过了时间的烤盐啊……</p>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
  </entry>
  <entry>
    <title>[论文阅读]Mind the Gap:Understanding the Modality Gap in</title>
    <url>/2023/09/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Mind-the-Gap-Understanding-the-Modality-Gap-in/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>预推免面试准备</title>
    <url>/2022/08/16/%E9%A2%84%E6%8E%A8%E5%85%8D%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/</url>
    <content><![CDATA[<h2 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0. 写在前面"></a>0. 写在前面</h2><p>准备思路：</p>
<ol>
<li>从自我介绍、科研经历、竞赛项目经历和未来研究兴趣几个方面进行思考和梳理。前后具有逻辑性：基本情况–&gt;本科基础、经历–&gt;兴趣、优势–&gt;读研规划。</li>
<li>对应准备一下英文版。</li>
<li>突出自己的重点、亮点。</li>
</ol>
<h2 id="1-自我介绍"><a href="#1-自我介绍" class="headerlink" title="1. 自我介绍"></a>1. 自我介绍</h2><p>​		中文版3分钟<br>​		英文版3分钟<br>​		中文版1分钟<br>​		英文版1分钟</p>
<p>​		Good morning, dear professor. It’s great honor to be here for the interview. My name is LiRuoxuan. Born in Hubei province, I feel lucky that I can finish my undergraduate education in Nanjing University of Science and Technology, from where I learned a lot. </p>
<p>​		Over the last three years, I was mainly concentrating on obtaining knowledge. Not only from books, but also from discipline competitions, community activities and countless others. learn to be with others and learn to how to learn. I try to improve myself under the direction of UNESCO. From my perspective, integrated development is crucial. I learned to build a sense of responsibility and I furthered my organizing capacity. Moreover, I devoted some time doing research in a group. Though we didn’t get significant achievement, the process led a way for me to pause, to look, to examine, to consider different aspects of a problem, and finally to figure out a solution without pursuing quick success and instant benefits. Further more, I did some part-time jobs which make me feel more confident and cheerful. </p>
<p>By doing all these above, I learned how to manage time. Although I have grasped the basic knowledge of my major, I admit that there is still a long way to go before I can undertake more demanding tasks or researching works, for my knowledge and ability is somewhat limited. So I believe further study is urgent for me .The major that I wish to pursue for my further education is intelligent perception and intelligent computing（智能感知与智能计算）. I plan to concentrate on study and research in this field in my graduate time. And I convince that I can form a systematic view of intelligent perception and intelligent computing, and make a solid foundation for future profession after three years study here! Thank you very much for your time!</p>
<h2 id="2-科研经历"><a href="#2-科研经历" class="headerlink" title="2. 科研经历"></a>2. 科研经历</h2><h2 id="3-项目问答"><a href="#3-项目问答" class="headerlink" title="3. 项目问答"></a>3. 项目问答</h2><h2 id="4-研究兴趣-amp-未来计划"><a href="#4-研究兴趣-amp-未来计划" class="headerlink" title="4. 研究兴趣 &amp; 未来计划"></a>4. 研究兴趣 &amp; 未来计划</h2><h2 id="5-常见提问（中英文版）"><a href="#5-常见提问（中英文版）" class="headerlink" title="5. 常见提问（中英文版）"></a>5. 常见提问（中英文版）</h2><h5 id="1-Introduce-yourself（1min-x2F-3min）"><a href="#1-Introduce-yourself（1min-x2F-3min）" class="headerlink" title="1. Introduce yourself（1min&#x2F;3min）"></a>1. Introduce yourself（1min&#x2F;3min）</h5><p>内容上，包括姓名、年龄、本科院校、专业，想去该校读研的原因，喜欢的研究方向以及自己学习这个方向的基础和优势，结束语句表达憧憬及感谢老师。</p>
<h5 id="2-Why-do-you-choose-A-University？（想来我校读研的原因）"><a href="#2-Why-do-you-choose-A-University？（想来我校读研的原因）" class="headerlink" title="2. Why do you choose A University？（想来我校读研的原因）"></a>2. Why do you choose A University？（想来我校读研的原因）</h5><p>Southeast University（东南大学）</p>
<h5 id="3-What’s-your-major-why-do-you-choose-it-and-what-do-you-think-of-it-（你所学专业，以及为何选择申请这个专业）"><a href="#3-What’s-your-major-why-do-you-choose-it-and-what-do-you-think-of-it-（你所学专业，以及为何选择申请这个专业）" class="headerlink" title="3. What’s your major,why do you choose it and what do you think of it?（你所学专业，以及为何选择申请这个专业）"></a>3. What’s your major,why do you choose it and what do you think of it?（你所学专业，以及为何选择申请这个专业）</h5><p>说一下自己学习这个专业方向的基础和优势，包括为此所作的准备等。</p>
<h5 id="4-What’s-your-plan-for-the-after-3-x2F-5-years-（未来计划）"><a href="#4-What’s-your-plan-for-the-after-3-x2F-5-years-（未来计划）" class="headerlink" title="4. What’s your plan for the after 3&#x2F;5 years?（未来计划）"></a>4. What’s your plan for the after 3&#x2F;5 years?（未来计划）</h5><p>未来研究方向包括大数据分析、强化学习、无人系统、物联网智能感知、多智能体系统、博弈理论等，培养学生用算法与优化方法解决应用问题的能力。</p>
<h5 id="5-Briefly-describe-your-scientific-research-experience-in-English（用英文简述科研经历）"><a href="#5-Briefly-describe-your-scientific-research-experience-in-English（用英文简述科研经历）" class="headerlink" title="5. Briefly describe your scientific research experience in English（用英文简述科研经历）"></a>5. Briefly describe your scientific research experience in English（用英文简述科研经历）</h5><h5 id="6-科研训练读过哪些期刊的相关论文？"><a href="#6-科研训练读过哪些期刊的相关论文？" class="headerlink" title="6. 科研训练读过哪些期刊的相关论文？"></a>6. 科研训练读过哪些期刊的相关论文？</h5><h5 id="7-读过什么专业类书"><a href="#7-读过什么专业类书" class="headerlink" title="7. 读过什么专业类书"></a>7. 读过什么专业类书</h5><h5 id="8-Tell-me-about-your-university（本科学校）"><a href="#8-Tell-me-about-your-university（本科学校）" class="headerlink" title="8. Tell me about your university（本科学校）"></a>8. Tell me about your university（本科学校）</h5><h5 id="9-Tell-me-about-your-hometown（家乡）"><a href="#9-Tell-me-about-your-hometown（家乡）" class="headerlink" title="9. Tell me about your hometown（家乡）"></a>9. Tell me about your hometown（家乡）</h5><h5 id="10-Tell-me-about-your-family（家庭）"><a href="#10-Tell-me-about-your-family（家庭）" class="headerlink" title="10. Tell me about your family（家庭）"></a>10. Tell me about your family（家庭）</h5><h5 id="11-优缺点"><a href="#11-优缺点" class="headerlink" title="11. 优缺点"></a>11. 优缺点</h5><h5 id="12-最喜欢的课程是哪门，简要介绍一下"><a href="#12-最喜欢的课程是哪门，简要介绍一下" class="headerlink" title="12. 最喜欢的课程是哪门，简要介绍一下"></a>12. 最喜欢的课程是哪门，简要介绍一下</h5><h5 id="13-本科有没有担任什么职务"><a href="#13-本科有没有担任什么职务" class="headerlink" title="13. 本科有没有担任什么职务"></a>13. 本科有没有担任什么职务</h5><h5 id="问题没听清-amp-听不懂时"><a href="#问题没听清-amp-听不懂时" class="headerlink" title="问题没听清&amp;听不懂时"></a>问题没听清&amp;听不懂时</h5><p>Sorry, I can’t follow you.<br>Sorry, I lost you. Can you repeat that question again?</p>
<p>Could you please make the question simpler?<br>Could you please express in a different way?</p>
<h2 id="6-专业基础知识"><a href="#6-专业基础知识" class="headerlink" title="6. 专业基础知识"></a>6. 专业基础知识</h2><p>英文描述快速排序过程以及最好最坏复杂度</p>
<p>数据库bc范式和第三范式区别</p>
<p>特征值和特征向量的意义以及之间的关系</p>
<p>TCP-IP的工作过程描述</p>
<p>在局域网中TCP-IP协议栈是否冗余</p>
<p>列举各种排序算法以及复杂度</p>
<p>数据结构快排的优缺点，怎样改进缺点</p>
<p>栈和队列的区别</p>
<p>如何用两个栈实现队列</p>
<p>很简单的双指针，把负数移到正数前。控制到On复杂度</p>
<p>Floyd(菜鸡用了复杂度比较高的方法)</p>
<p>很简单的动态规划</p>
<p>询问什么情况下要使用动态规划？</p>
<p>TCP和UDP之间的区别</p>
<p>解释什么是中心极限定理</p>
<p>C++虚函数的原理</p>
<p>你科研训练中用到的算法以及对科研项目其他的算法是否有了解？</p>
<p>怎样快速找到数组中第k大的数？</p>
<p>讲讲你在数学建模中是如何处理数据的？</p>
<ol>
<li>操作系统</li>
</ol>
<p>（1）磁盘，空闲空间的管理方案和磁盘的存储等一些计算。</p>
<p>（2）页式管理，页号的计算、物理和逻辑存储地址几位，以及访问快表时的命中率为N时，时间为多少.</p>
<p>（3）处理器调度问题，涉及优先级调度，最短作业调度，时间片轮转，用甘特图表示出来，需要注意的是cpu的数量，我做的题目是两个CPU；</p>
<ol start="2">
<li>数据结构（主要是各个算法的思想）</li>
</ol>
<p>（1）归并排序，内部排序（排序方法在内存中进行），外排序为什么不用多路归并。</p>
<p>（2）AVL平衡树旋转，从一个状态插入、删除一个数时，最多旋转几次。</p>
<p>（3）二叉树，证明二度节点数与零度节点数的关系。</p>
<p>（4）回文链，设计一个算法证明一个链时回文链，使得时间复杂度为O(n)空间复杂度为O(1)。</p>
<p>（5）最短路径算法，具体实现中的细节小问题。</p>
<h2 id="7-专业术语（英文）"><a href="#7-专业术语（英文）" class="headerlink" title="7. 专业术语（英文）"></a>7. 专业术语（英文）</h2>]]></content>
      <categories>
        <category>上岸之旅</category>
      </categories>
      <tags>
        <tag>保研面试</tag>
      </tags>
  </entry>
</search>
